\mtcaddchapter
\chapter{Native AI Integration with `by' and `sem' Keywords}
\minitoc

While the previous chapter established Jac's foundations as a superset of Python, this chapter explores what truly sets Jac apart: its implementation of \emph{meaning-typed programming} (MTP) through native AI integration. Rather than treating AI as an external library or service, Jac makes AI a first-class citizen in the language itself through the `by` and `sem` keywords, which realize the MTP paradigm by leveraging the inherent semantic richness of code to automate LLM integration.

This approach represents a fundamental shift from traditional prompt engineering to meaning-typed programming. Instead of complex API calls, manual prompt crafting, and explicit result parsing, Jac's MTP implementation provides declarative constructs that automatically extract semantic meaning from code structure—function names, parameter types, return types, and contextual annotations—to generate appropriate prompts and handle AI interactions. The `by` keyword delegates implementation to AI models based on inferred intent, while the `sem` keyword provides additional semantic context that enriches the meaning available to the AI system.

The power of this approach becomes apparent when you consider the cognitive load reduction. Traditional AI programming requires constant context switching between your application logic and the mechanics of AI interaction—crafting prompts, handling API responses, parsing unstructured output, and managing errors. Jac abstracts these concerns away, letting you focus on what you want the AI to do rather than how to make it happen. The result is code that reads like a specification of intent rather than a series of implementation details.

As you work through this chapter, you'll discover how Jac's AI constructs compose naturally with all the language features you learned in the previous chapter. AI-powered functions work seamlessly with Jac's type system, participate in object-oriented designs, integrate with concurrency primitives, and benefit from the same tooling and debugging support as regular code. By the end, you'll understand how to build AI applications that are not only powerful but also maintainable, testable, and scalable.

\section{The `by' Keyword: Delegating Implementation to AI}

The `by` keyword realizes the core principle of meaning-typed programming: leveraging the semantic richness inherent in code to automate AI integration. When you append `by llm()` to a function signature, Jac's MTP system automatically extracts semantic meaning from the function's name, parameter types, return type, and surrounding context to generate appropriate prompts for the AI model. This eliminates the need for manual prompt engineering while ensuring the AI understands the intended functionality.

This represents the fundamental insight of MTP: programs are written to be readable by developers, and this same semantic richness can be automatically translated into prompts for LLMs. The `by` keyword transforms function signatures from mere type declarations into rich semantic specifications that AI models can interpret and implement. This shift from imperative implementation to declarative intent opens up entirely new possibilities for rapid prototyping, domain-specific functionality, and adaptive behavior.

\subsection{Basic Function Delegation}

The simplest use of the `by` keyword transforms a function signature into an AI-powered implementation. The AI model uses the function's name, parameter types, return type, and any available context to infer the intended behavior.

\begin{jacblock}
import from byllm { Model }

glob llm = Model(model_name="gpt-4o");

def translate(input: str, lang: str = "French") -> str by llm();

with entry {
    print(translate("I am a student", "French"));   # "Je suis un etudiant"
    print(translate("I am a student", "Spanish"));  # "Soy un estudiante"
}
\end{jacblock}

In this example, the AI model infers from the function name `translate`, the parameters `input` and `lang`, and the return type `str` that this function should translate text from one language to another. No explicit prompt engineering or response parsing is required—Jac handles the entire interaction based on the function's type signature.

The power of this approach becomes evident when you consider how much boilerplate it eliminates. Traditional AI integration would require constructing prompts, making API calls, parsing responses, handling errors, and converting results to the appropriate types. The `by` keyword encapsulates all of this complexity behind a clean, typed interface.

\subsection{Method Delegation in Objects}

The `by` keyword works seamlessly with Jac's object system, allowing you to create AI-powered methods that have access to the object's state and context. This enables sophisticated AI behaviors that are contextually aware of the data they're operating on.

\begin{jacblock}
import from byllm { Model }

glob llm = Model(model_name="gpt-4o");

obj Essay {
    has essay: str;

    def essay_judge(criteria: str) -> str by llm();
    def generate_summary(judgements: dict) -> str by llm();
    def give_grade(summary: str) -> str by llm();
}

with entry {
    essay = Essay("With a population of approximately 45 million...");
    criterias = ["Clarity", "Originality", "Evidence"];
    judgements = {};

    for criteria in criterias {
        judgement = essay.essay_judge(criteria);
        judgements[criteria] = judgement;
    }

    summary = essay.generate_summary(judgements);
    grade = essay.give_grade(summary);
    print("Grade:", grade);
}
\end{jacblock}

Here, the AI-powered methods have access to the essay's content through \texttt{self.essay}, enabling contextually relevant evaluation. The \texttt{essay\_judge} method can analyze the specific essay content against the given criteria, while \texttt{generate\_summary} can synthesize multiple judgements into a coherent assessment. This object-oriented approach to AI delegation creates natural, reusable abstractions for complex AI workflows.

\subsection{Advanced Configuration Options}

The `by` clause accepts various configuration options that control the AI model's behavior, reasoning approach, and integration with external tools. These options provide fine-grained control over the AI's operation while maintaining the declarative simplicity of the basic syntax.

\begin{jacblock}
import from byllm { Model }

glob llm = Model(model_name="gpt-4o-mini");

enum Personality { INTROVERT, EXTROVERT }

glob personality_examples: dict[str, Personality] = {
    'Albert Einstein': Personality.INTROVERT,
    'Barack Obama': Personality.EXTROVERT
};

def get_person_info(name: str) -> Person by llm(
    reason=True,                    # Enable chain-of-thought reasoning
    temperature=0.0,                # Deterministic output
    incl_info={"personality_examples": personality_examples}
);
\end{jacblock}

The configuration options allow you to:
\begin{itemize}
    \item Control randomness with \texttt{temperature}
    \item Enable reasoning modes like \texttt{reason=True} or \texttt{method="Chain-of-Thoughts"}
    \item Provide additional context through \texttt{incl\_info}
    \item Specify maximum iterations for reasoning processes
    \item Include external tools for the AI to use
\end{itemize}

These options transform the simple `by llm()` clause into a powerful specification for exactly how the AI should approach the problem, while still maintaining the clean abstraction that hides implementation complexity.

\subsection{Complex Return Types and Structured Output}

One of Jac's most powerful AI features is automatic handling of complex, structured return types. When you specify that an AI-powered function should return a custom object, enum, or complex data structure, Jac automatically handles the serialization and parsing, ensuring type safety throughout the AI interaction.

\begin{jacblock}
obj Employer {
    has employer_name: str,
        location: str;
}

obj Person {
    has name: str,
        age: int,
        employer: Employer,
        job: str;
}

def generate_person(info: str) -> Person by llm();

with entry {
    person = generate_person(
        "Steve Jobs was 56 years old and worked as the CEO of Apple Inc. in California."
    );
    print(f"Person's name is {person.name} and works at {person.employer.employer_name}");
}
\end{jacblock}

In this example, the AI model automatically extracts structured information from unstructured text and returns a properly typed `Person` object with nested `Employer` data. Jac handles the entire process of:
\begin{itemize}
    \item Communicating the expected structure to the AI model
    \item Parsing the AI's response into the correct object types
    \item Validating that all required fields are present and correctly typed
    \item Providing meaningful error messages if parsing fails
\end{itemize}

This structured output capability eliminates one of the biggest pain points in AI programming: converting unstructured AI responses into structured data that your application can use reliably.

\section{The `sem' Keyword: Semantic Annotations and Context}

While the `by` keyword handles the mechanics of AI delegation by extracting inherent semantic meaning from code structure, the `sem` keyword extends MTP by allowing developers to provide additional semantic context that enriches the meaning available to AI models. This addresses one of the key challenges in meaning-typed programming: ensuring AI models have sufficient semantic information for accurate task performance.

The `sem` keyword represents MTP's approach to bridging the gap between code semantics and AI understanding. Unlike traditional comments that are ignored by the runtime, semantic annotations become part of the program's execution context within the MTP system, directly influencing how AI models interpret intent and generate appropriate responses. This creates a rich semantic environment where both implicit meaning (from code structure) and explicit meaning (from annotations) work together to guide AI behavior.

\subsection{Function Documentation with Semantic Context}

Semantic annotations on functions provide detailed specifications that guide AI implementation. These annotations can include examples, constraints, behavioral requirements, and domain-specific knowledge that helps the AI produce more accurate and contextually appropriate results.

\begin{jacblock}
def generate_password() -> str by llm();
sem generate_password = """\
Generates and returns password that:
    - contain at least 8 characters
    - contain at least one uppercase letter
    - contain at least one lowercase letter
    - contain at least one digit
    - contain at least one special character
""";

with entry {
    password = generate_password();
    print('Generated password:', password);  # R8@jL3pQ
}
\end{jacblock}

The semantic annotation provides explicit requirements that the AI model uses to generate appropriate passwords. This approach is far more reliable than hoping the AI will infer password requirements from the function name alone. The annotation becomes part of the function's contract, ensuring consistent behavior across different AI models and contexts.

\subsection{Data Structure Semantics}

Semantic annotations on data structures provide context about the meaning and usage of fields, helping AI models understand the domain-specific significance of different data elements.

\begin{jacblock}
obj Person {
    has full_name: str,
        yod: int,
        personality: Personality;
}
sem Person.yod = "Year of Death of the person";

enum Personality { INTROVERT, EXTROVERT }

glob personality_examples: dict[str, Personality] = {
    'Albert Einstein': Personality.INTROVERT,
    'Barack Obama': Personality.EXTROVERT
};
\end{jacblock}

The semantic annotation clarifies that `yod` represents "Year of Death," preventing potential confusion with other year-related fields. This contextual information helps AI models make more accurate inferences when working with `Person` objects, especially when extracting information from unstructured sources.

\subsection{Examples and Training Data}

Semantic annotations can include examples that serve as few-shot learning data for AI models. These examples provide concrete illustrations of expected input-output relationships, dramatically improving the quality and consistency of AI-generated results.

\begin{jacblock}
obj OddWord {
    has options: list[str];
    has reasoning: str;
    has result: str;
}

glob examples: list[OddWord] = [
    OddWord(options=["skirt", "dress", "pen", "jacket"],
            reasoning="skirt is clothing, dress is clothing, pen is an object, jacket is clothing.",
            result="pen"),
    OddWord(options=["Spain", "France", "German", "England", "Singapore"],
            reasoning="Spain, France, England, Singapore is a country, German is a language.",
            result="German"),
];
sem examples = "Examples for Picking Odd Word out (Options, Reasoning, Result)";

def odd_word_out_and_reason(options: list[str]) -> OddWord by llm(
    incl_info={"examples": examples}
);
\end{jacblock}

The examples provide the AI model with concrete patterns to follow, including the expected reasoning process. This few-shot learning approach often produces more consistent and higher-quality results than relying on the model's general training alone.

\subsection{Tool and Function Semantics}

When integrating external tools or functions with AI models, semantic annotations provide crucial context about what each tool does and when it should be used. This guidance helps AI models make appropriate tool selection decisions.

\begin{jacblock}
def get_wikipedia_summary(title: str) -> str {
    try {
        return wikipedia.summary(title);
    } except Exception {
        options = wikipedia.search(title, results=5, suggestion=True);
        raise Exception(f"Could not get summary for {title}. Similar titles: {options}");
    }
}
sem get_wikipedia_summary = """Get the summary of the related article from Wikipedia.""";

def get_answer(question: str) -> str by llm(tools=[get_wikipedia_summary]);
\end{jacblock}

The semantic annotation clearly describes the tool's purpose and behavior, helping the AI model understand when and how to use it effectively. Without this context, the AI might misunderstand the tool's capabilities or use it inappropriately.

\section{Multimodal AI: Images, Video, and Beyond}

Jac's AI integration extends beyond text to support multimodal AI models that can process images, videos, and other media types. The same declarative approach that makes text-based AI simple also applies to multimodal scenarios, with automatic handling of media loading, encoding, and processing.

\subsection{Image Processing}

Images are treated as first-class data types in Jac's AI system. The `Image` type automatically handles loading, encoding, and transmission to AI models, while maintaining the same clean interface as text-based operations.

\begin{jacblock}
import from byllm { Model, Image }
import os;

glob llm = Model(model_name="gpt-4o");

def solve_math_question(question_img: Image) -> str by llm(method="Chain-of-Thoughts");

with entry {
    question_img = Image(
        os.path.join(os.path.dirname(__file__), 'math_question.jpg')
    );
    print(solve_math_question(question_img));
}
\end{jacblock}

The AI model can analyze the mathematical problem in the image and provide step-by-step solutions using chain-of-thought reasoning. This capability opens up applications in document analysis, visual question answering, and automated content understanding.

\subsection{Video Analysis}

Video processing follows the same pattern as image processing, with additional parameters for controlling frame sampling and processing efficiency.

\begin{jacblock}
import from byllm { Model, Video }
import os;

glob llm = Model(model_name="gpt-4o");

def explain_the_video(video: Video) -> str by llm();

with entry {
    video_file_path = os.path.join(os.path.dirname(__file__), "sample_video.mp4");
    target_fps = 1;  # Sample 1 frame per second
    video = Video(path=video_file_path, fps=target_fps);
    print(explain_the_video(video));
}
\end{jacblock}

The `Video` type handles the complexity of video processing, including frame extraction, encoding, and transmission to the AI model. The `fps` parameter allows you to control the sampling rate, balancing detail with processing efficiency.

\section{Advanced AI Patterns}

As applications become more sophisticated, Jac provides advanced patterns for complex AI interactions, including tool integration, reasoning methods, and multi-agent systems.

\subsection{Tool Integration and Function Calling}

AI models can be equipped with external tools that extend their capabilities beyond pure language processing. These tools can be regular Python functions, API calls, or any callable that provides additional functionality.

\begin{jacblock}
import wikipedia;

def get_wikipedia_summary(title: str) -> str {
    try {
        return wikipedia.summary(title);
    } except Exception {
        options = wikipedia.search(title, results=5, suggestion=True);
        raise Exception(f"Could not get summary for {title}. Similar titles: {options}");
    }
}

def ask_opponent(statement: str) -> str {
    user_input = input(f"AI -> {statement} ");
    return f"Opponents Answer -> {user_input}";
}

def debate_agent(topic: str) -> str by llm(
    tools=[get_wikipedia_summary, ask_opponent],
    context=[
        "You have to defend the given topic while the opponent is defending the counter topic",
        "If you dont know about the topic use the given tools",
        "You are a humorous, cunning, very arrogant debater.",
    ]
);
\end{jacblock}

The AI model can dynamically choose which tools to use based on the conversation context, creating interactive and adaptive behaviors that respond to real-time inputs and external data sources.

\subsection{Reasoning Methods}

Different AI tasks benefit from different reasoning approaches. Jac supports various reasoning methods that can be specified in the `by` clause to optimize the AI's problem-solving approach.

\begin{jacblock}
def get_expert(question: str) -> str by llm(method='Reason');
def get_answer(question: str, expert: str) -> str by llm();

# ReAct (Reasoning + Acting) pattern for complex tasks
def complex_analysis(requirements: str) -> str by llm(
    method="ReAct",
    tools=[wikipedia_summary, search, scrape],
    max_react_iterations=10,
    context=["DONOT SUMMARIZE. MAKE IT DETAILED"]
);
\end{jacblock}

Different reasoning methods include:
\begin{itemize}
    \item `Reason`: Basic chain-of-thought reasoning
    \item `Chain-of-Thoughts`: Explicit step-by-step reasoning
    \item `ReAct`: Reasoning and Acting pattern for tool-using agents
\end{itemize}

Each method optimizes the AI's approach for different types of problems, from simple analysis to complex multi-step reasoning with external tool integration.

\subsection{Multi-Agent Systems}

Jac's AI constructs compose naturally to create multi-agent systems where different AI-powered functions represent specialized agents with distinct roles and capabilities.

\begin{jacblock}
def persona_expert(requirements: str) -> str by llm(
    method="ReAct",
    tools=[wikipedia_summary, search, scrape],
    context=["DONOT SUMMARIZE. MAKE IT DETAILED"]
);

def market_expert(requirements: str) -> str by llm(
    method="ReAct",
    tools=[wikipedia_summary, scrape, search],
    context=["DONOT SUMMARIZE. MAKE IT DETAILED"]
);

def manager(query: str) -> str by llm(
    method="ReAct",
    tools=[persona_expert, market_expert, search, scrape],
    context=["DONOT SUMMARIZE. MAKE IT DETAILED"]
);
\end{jacblock}

In this example, specialized expert agents handle domain-specific analysis, while a manager agent coordinates their work and synthesizes results. This hierarchical approach enables complex analysis workflows that leverage specialized expertise while maintaining overall coherence.

\section{Best Practices and Patterns}

Effective use of Jac's AI constructs requires understanding both the capabilities and limitations of the underlying AI models, as well as patterns that lead to reliable and maintainable AI-powered applications.

\subsection{Type Safety and Error Handling}

Jac's type system provides crucial guardrails for AI interactions. Always use specific, well-defined types for AI function parameters and return values, as this helps both the AI model understand expectations and your application handle results reliably.

\begin{jacblock}
# Good: Specific, typed interface
def analyze_sentiment(text: str) -> Sentiment by llm();

# Better: Include constraints and examples
enum Sentiment { POSITIVE, NEGATIVE, NEUTRAL }
def analyze_sentiment(text: str) -> Sentiment by llm(
    incl_info={"examples": sentiment_examples}
);
\end{jacblock}

\subsection{Context Management}

Provide sufficient context through semantic annotations, examples, and the \texttt{incl\_info} parameter. AI models perform better when they understand the domain, expected behavior, and have concrete examples to follow.

\subsection{Testing AI Functions}

AI functions can be tested like any other function, but require special consideration for their non-deterministic nature. Use mock LLM instances for deterministic testing:

\begin{jacblock}
# For testing
glob test_llm = Model(
    model_name="mockllm",
    outputs=["expected_output"]
);

def testable_function(input: str) -> str by test_llm();
\end{jacblock}

\subsection{Performance Considerations}

AI operations are inherently slower than traditional computation. Design your applications to handle this latency appropriately, consider caching strategies for repeated operations, and use Jac's concurrency features to parallelize independent AI calls.

\begin{jacblock}
# Parallel AI operations
tasks = [flow analyze_text(text) for text in texts];
results = [wait task for task in tasks];
\end{jacblock}

The integration of AI into Jac's core language constructs represents a fundamental shift toward more declarative, intention-driven programming. By treating AI as a first-class language feature rather than an external service, Jac enables developers to focus on what they want to accomplish rather than the mechanics of AI integration. This approach not only reduces complexity but also creates new possibilities for adaptive, intelligent applications that can evolve and respond to changing requirements with minimal code changes.
